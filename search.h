/*
* search.h
* 
* 用于学习查找表及查找算法相关知识
*/
#ifndef _WYL_SEARCH
#define _WYL_SEARCH

#include <stdio.h>
#include <stdlib.h>
#include "unidef.h"
#include "tree.h"
#include "linear_list.h"

//
// 查找表
// 
// 背景：
//	在数据结构中，数据之间的逻辑关系可以归纳为 4 种：一对一、一对多、多对多、无关系。
// 
//	我们使用线性结构（线性表）存储“一对一”关系的数据，使用树结构存储“一对多”关系的数
//	据，使用图结构存储“多对多”关系的数据，而对于无逻辑关系的数据，我们使用查找表存储。
// 
//	现实生活中，无逻辑关系的数据是很常见的，比如字典中的汉字、电话簿中的电话号码等。
// 
// 定义：
//	查找表是一种存储结构，用来存储无逻辑关系的数据。或者说，查找表是一个包含众多元素
//	的集合，表中的各个元素独立存在，相互之间没有任何关系。
// 
//	对于无逻辑关系的数据，最常见的操作就是查找某个特定的元素。和有逻辑关系的数据相比，
//	在无逻辑关系的数据中查找特定元素的难度更大。例如，同样是查找一个电话号码，在杂乱
//	无章的电话簿中查找既费时又费力，在有序的电话簿中很快就能找到。
// 
//	原本没有逻辑关系的数据，为了提高查找效率，会人为地给数据赋予一种逻辑关系，然后选用
//	线性表、树或者图结构来存储数据。比如说，为电话簿中的电话号码赋予“一对一”的关系，就
//	可以用线性表（顺序表或者单链表）来存储电话号码。
// 
//	从名称上看，查找表是一种新的存储结构，但实际上它指的就是用线性表、树或者图结构来存储
//	数据，只不过数据间的逻辑关系是人为赋予的。
// 
//	数据结构中，将存储无逻辑关系数据的线性表、树或者图结构统称为查找表。
// 
// 分类：
//	静态查找表：只进行查找和读取操作，不改变表的存储结构；
//	动态查找表：除查找和读取外，还进行插入和删除操作，会改变表的存储结构；
//	动态查找表可以在查找过程中动态建立，静态查找表只能先建立再执行查找操作。
// 
// 存储：
//	静态查找表：线性表、索引顺序表、静态树表；
//	动态查找表：二叉排序树、平衡二叉树。
// 
// 算法性能：
//	算法的好坏可以从时间复杂度和空间复杂度两个维度衡量。对于查找算法来说，查找过程中只
//	需要少量的辅助存储空间，各个查找算法的空间复杂度区别不大。多数情况下，我们通过时间
//	复杂度衡量查找算法的好坏。
// 
//	对于查找算法来说，影响其时间复杂度的主要是比较次数，因此，可以直接用比较次数的平均
//	值（又称平均查找长度，简称 ASL）作为衡量查找算法好坏的依据。
// 
//	ASL = [找到第 i 各元素的概率 * 比较过第 i 个元素后的总比较次数] 的累和。ASL 越
//	小，表明查找算法的性能越好，执行效率越高。
// 

/*
* 基于线性结构的查找表
*/
typedef struct
{
	ElemType* earr;
	int length;
}SSTable;

//
// 顺序查找（Sequential Search）
// 
// 定义：
//	从查找表的一端开始，将表中的元素逐一和目标元素做比较，直至找到目标元素。
// 
// 实现：
//	常规的实现思路是：将表中元素逐一和目标元素比较，如果不相等，则判断整张表是否查找完毕，
//	如果还有未比较的元素，就继续比较，反之算法执行结束。
// 
//	常规的实现思路，每次查找都要进行两次判断，既要判断当前元素是否为目标元素，还要判断整
//	张表是否查找完毕。可以通过更高效的实现思路，实现每次查找只进行一次判断。
// 
//	高效的实现思路是：在查找表的一端（头或尾）添加目标元素，从表的另一端（尾或头）开始进行
//	顺序查找，查找过程中不必判断整张表是否查找完毕，从而提升效率。之所以不用判断整张表是否
//	查找完毕，是因为在表内肯定能找到目标元素，只不过找到的目标元素可能是我们添加的（相当于
//	没找到）。数据结构中，将人为添加到查找表一端的目标元素，称为监视哨。
// 
// 性能：
//	顺序查找算法的时间复杂度是 O(n)，平均查找长度是 (n+1)/2。
// 
// 特点：
//	顺序查找简单直接，适用于绝大多数场景，查找表中存放有序序列或无序序列都适用。缺点是性能
//	一般，查找表中元素数量越多，算法性能越差。
// 
// 应用：
//	顺序查找适用于线性存储结构实现的静态查找表，查找过程不涉及元素的插入和删除操作。
//

/*
* 顺序查找
* 
* 返回 key 在查找表中的位置，失败返回 -1
*/
int SearchSeq(SSTable st, ElemType key);

//
// 二分查找
// 
// 定义：
//	二分查找又称折半查找，通过不断地将有序查找表“一分为二”，逐渐缩小搜索区域，进而找到目标元素。
// 
// 实现：
//	1. 对于一个有序（假设为升序）查找表，初始状态下，搜索区域为整个查找表；
//	2. 用 low 记录搜索区域第一个元素位置，用 high 记录搜索区域最后一个元素位置；
//	3. 计算 (low+high)/2 的向下取整结果，获得搜索区域中间元素的位置 mid；
//	4. 比较目标元素和中间元素：
//		目标 > 中间，更新 low = mid + 1，high 不变；
//		目标 = 中间，找到目标元素，返回对应位置 mid；
//		目标 < 中间，low 不变，更新 high = mid - 1；
//	5. 重复 3-4 直至找到目标元素或 low > high（及查找失败）。
// 
// 性能：
//	二分查找的时间复杂度为 O(logn)，平均查找长度为 log(n+1) - 1（借助二叉树，或称判定树计算）。
// 
// 特点：
//	二分查找要求查找表有序，升序或降序都可。适用场景不如顺序查找，但二分查找的效率更高。
// 
// 应用：
//	顺序查找适用于线性存储结构实现的静态查找表，且查找表必须是有序的，查找过程不涉及元素的插入和删除操作。
//

/*
* 二分查找
* 
* 返回 key 在查找表中的位置，失败返回 -1
*/
int SearchBin(SSTable st, ElemType key);

//
// 分块查找
// 
// 定义：
//	分块查找又称索引顺序查找，通过将分块有序的查找表分成若干子表，并为每个子表配备一个索引，从而缩小
//	查找范围，提升查找效率。所谓分块有序是指某个子表中的元素都要大于（或小于）其相邻子表中的元素，而
//	该子表内部的元素可以是无序的。
// 
// 实现：
//	1. 定义索引结构体，包含两个元素：key（同查找表数据同类型）、start（整型）；
//	2. 将查找表平均分为若干子表，为每个子表建立一个索引，记录该子表中的最大值以及该子表的起始位置；
//	3. 对索引表进行二分查找，确定目标元素可能存在的子表；
//	4. 对子表进行顺序查找，确定目标元素位置。
// 
// 特点：
//	分块查找要求查找表分块有序，即该查找表可以划分为若干子表，每个子表中的元素，均大于（或小于）其相邻
//	子表中的元素，而子表内部的元素可以是无序的。
// 
// 性能：
//	分块查找的性能介于顺序查找和二分查找之间。
//

/*
* 用于分块查找的索引结构体
*/
typedef struct
{
	ElemType max; // 子表中的最大元素
	int start; // 子表的开始位置
}Index;

/*
* 分块查找
*/
int SearchBlk(SSTable st, ElemType key);

//
// 次优查找树查找
// 
// 术语：
//	查找树：
//		又称判定树，是一棵二叉树。对有序数据的查找，不论基于哪种比较策略（顺序、折半），都可以用一棵二叉树
//		表示。查找过程就是从根结点出发，根据比较结果，决定继续向左（右）子树查找或是停止。查找树的平均查找
//		长度（又称查找树的带权路径长度之和 PH） = [(每个结点的查找概率 * 该结点所在层次之积) 之总和]。
//	最优查找树：
//		对于给定的结点及结点查找概率，构建出的平均查找长度最小的查找树。
//	次优查找树：
//		构造最优查找树的时间代价很高，有一种简单方式构建出的查找树其查找性能相比最优查找树仅差 1%-2%，称该
//		种方式构造出的查找树为次优查找树。
// 
// 定义：
//	根据给定的有序表及表中各关键字的查找概率，构建次优查找树，通过次优查找树完成指定关键字的查找。
// 
// 实现：
//	构建次优查找树：
//		1. 根据给定的有序表，对每个关键字 K，计算 P = |K 右侧关键字概率之和 - K 左侧关键字概率之和|；
//		2. 找出最小 P，以其对应的 K 作为本次构造出的根结点，然将有序表以 K 为分割点分为左右两个子有序表；
//		3. 将左右子有序表作为给定有序表，重复执行 1-3，直至当次最小 P' 对应的 K' 位于表头或表尾，完成 K 的左右子树构建。
//	次优查找树查找：
//		先序遍历次优查找树，直至找到指定的关键字，或者无法找到。
// 
// 特点：
//	次优查找树适用于有序表中各关键字的查找概率不同的场景。可用来表示概率不等的查找表对应的静态查找表（又称静态树表）。
// 
// 性能：
//	构造次优查找树的算法时间复杂度为 O(nlogn)。
//

/*
* 次优查找树查找
* 
* karr 有序存放关键字，parr 存放各关键字的查询概率，len 为 karr 和 parr 的长度
*/
int SearchOpt(ElemType karr[], float parr[], int len, ElemType key);

//
// 二叉排序树
// 
// 定义：
//	二叉排序树（Binary Sort Tree，BST）又称二叉查找树或二叉搜索树，是一种实现动态查找表的树型存储结构。
// 
//	二叉排序树本质是一棵二叉树，其特殊之处在于：
//		1. 对于树中每个结点，若其有左子树，则左子树上的所有结点的值都比该结点小；
//		2. 对于树中每个结点，若其有右子树，则右子树上的所有结点的值都比该结点大。
// 
//	二叉排序树中不存在值相同的结点，或者说，二叉排序树中每个结点的值都不相等。
// 
// 操作：
//	1. 查找（SearchBST）
//		从根结点出发，依次和目标元素做比较：
//		(1).若当前结点不存在，则查找失败；
//		(2).若目标元素等于当前结点的值，查找成功；
//		(3).若目标元素小于当前结点的值，进入左子树，继续查找；
//		(4).若目标元素大于当前结点的值，进入右子树，继续查找。
//	2. 插入（InsertBST）
//		插入的元素必须是原二叉排序树中没有的，且插入后整棵树还是一棵二叉排序树：
//		(1).在二叉排序树中查找要插入的新元素；
//		(2).若能找到，说明已有相同元素，插入失败；
//		(3).若未找到，则查找失败时到达的位置，就是放置新元素的位置。
//	3. 删除（DeleteBST）
//		删除的元素必须是原二叉排序树中已有的，且删除后整棵树还是一棵二叉排序树：
//		(1).在二叉排序树中查找要删除的元素；
//		(2).若未找到，删除失败；
//		(3).若能找到，设需要删除的结点为 P，则：
//			i.若 P 是叶子结点，则如果 P 是其双亲结点的左孩子，则将 P 双亲的左孩子设为 NULL，反之，
//			将 P 双亲的右孩子设为 NULL，然后释放 P 所占内存；
//			ii.若 P 只有一个孩子，则如果 P 是其双亲结点的左孩子，则将 P 的孩子作为 P 双亲的左孩子，
//			反之，将 P 的孩子作为 P 双亲的右孩子，然后释放 P 所占内存；
//			iii.若 P 有两个孩子，则在中序序列里找到 P 的直接前驱 S（在二叉排序树中，对于拥有两个孩
//			子的结点，其直接前驱要么是叶子结点，要么是只有左孩子的结点）。将 S 的值设置给 P，然后根
//			据 S 是叶子结点还是只有一个孩子的结点，按照 i 或 ii 的规则删除 S。
// 
// 性能：
//	二叉排序树的平均查找长度（ASL）和树的形态有关。元素的查找概率相同时，二叉排序树的层级越少，性能越高。
// 
//	二叉排序树的形态和给定的元素序列有关，比如分别以 {3, 2, 4, 1, 5} 和 {1, 2, 3, 4, 5} 构建二叉排
//	序树，前者构建的是一棵层级为 3 且左右子树均有的二叉树，后者构建的是一棵层级为 5 且只有右子树的二叉树。
// 
//	最好情况下，二叉排序树的查找时间复杂度是 O(logn)；最坏情况下，二叉排序树的查找时间复杂度是 O(n) 。
//

/*
* 二叉排序树查找元素
* 
* (*p_pos) 是指向 key 所在结点的指针
*/
void SearchBST(BiTree bt, ElemType key, BiTree* p_pos);

/*
* 二叉排序树插入元素
*/
void InsertBST(BiTree* p_bt, ElemType key);

/*
* 二叉排序树删除元素
*/
void DeleteBST(BiTree* p_bt, ElemType key);

//
// 平衡二叉树
// 
// 背景：
//	二叉排序树的性能取决于其形态，而其形态跟构建时使用的数据排序有关，最坏情况下会构造出只有左子树或只有右子树
//	的二叉排序树，使查询效率达到 O(n) 而不是 O(logn)。为了解决这个问题，两位数学家 G. M. Adelson-Velsky
//	和 Evgenii Landis 提出了平衡二叉树的概念，因此平衡二叉树又被称为 AVL 树。
// 
// 定义：
//	平衡二叉树是一棵二叉树，其特殊之处在于：对于树中任一顶点，其左子树和右子树的深度差不大于 1（只能为 -1、0、1）。
// 
//	平衡因子：顶点的 [左子树深度 - 右子树深度] 得到的差值，称为顶点的平衡因子（简称 BF），其值只能是：-1、0、1。
// 
//	注意：平衡二叉树虽然是为解决二叉排序树的最坏形态问题提出的，但就其定义来说，并不要求平衡二叉树必须是二叉排序树。
// 
// 应用：
//	在不破坏二叉排序树本身结构的情况下，将其转化为平衡二叉树，即最终变为平衡二叉排序树，可以解决普通二叉排序树在
//	存储和操作动态查找表时可能出现的最差效率的问题。下方所说的平衡二叉树，若未特殊说明，均指平衡二叉排序树。
// 
// 构建：
//	构建平衡二叉排序树时，若插入某个结点后，出现了 |BF| > 1 的结点，则树的平衡遭到破坏，需要通过“旋转”进行修正。
// 
//	我们称以距离插入结点最近的 |BF| > 1 的结点为根结点的子树，为“最小不平衡子树”，则要恢复到平衡状态，只需旋转修
//	正该“最小不平衡”子树即可。
// 
//	设“最小不平衡子树”的根结点为 P，左孩子为 L， 右孩子为 R，那么造成不平衡的情况，共分为 4 种：
//		LL：因将结点插入 L 的左子树，导致 P 的 |BF| > 1；
//		LR：因将结点插入 L 的右子树，导致 P 的 |BF| > 1；
//		RL：因将结点插入 R 的左子树，导致 P 的 |BF| > 1；
//		RR：因将结点插入 R 的右子树，导致 P 的 |BF| > 1。
// 
//	不论是上述哪种情况造成的不平衡，均需通过“旋转”特定的结点来进行修正，对结点 P 来说：
//		左旋：P 作为 R 的左孩子，R 原来的左孩子作为 P 的右孩子，L 依然为 P 的左孩子，R 代替 P 成为根结点，
//			（可以想象为：P 以 R 为轴心，逆时针进行旋转）；
//		右旋：P 作为 L 的右孩子，L 原来的右孩子作为 P 的左孩子，R 依然为 P 的右孩子，L 代替 P 成为根结点，
//			（可以想象为：P 以 L 为轴心，顺时针进行旋转）。
// 
//	具体来说：
//		对 LL 型失衡：P 右旋；
//		对 LR 型失衡：先 L 左旋，再 P 右旋；
//		对 RL 型失衡：先 R 右旋，再 P 左旋；
//		对 RR 型失衡：P 左旋。
// 
// 性能：
//	使用平衡二叉排序树进行查找的时间复杂度为 O(logn)。
//

/*
* AVL 树结点结构体
* 
* 对比二叉树结点结构体只多一个记录结点平衡因子的成员，以减少计算，提升效率
*/
typedef struct AVLNode
{
	ElemType e;
	struct AVLNode* p_lch;
	struct AVLNode* p_rch;
	int bf; // 记录结点的平衡因子，即结点 [左子树深度 - 右子树深度] 的差值，其值只能为 -1、0、1
}AVLNode, *AVLTree;

/*
* 左旋 p_avt 树的根结点
*/
void LeftRotate(AVLTree* p_avt);

/*
* 右旋 p_avt 树的根结点
*/
void RightRotate(AVLTree* p_avt);

/*
* 平衡二叉树插入元素
* 
* p_deeper 是指向记录本次插入对应的 p_avt 树的深度是否增加的标识的指针
* 
* 插入成功返回 1，插入失败返回 0
*/
int InsertAVL(AVLTree* p_avt, ElemType e, int* p_deeper);

/*
* 平衡二叉树查找元素
* 
* (*p_pos) 是指向 key 所在结点的指针
*/
void SearchAVL(AVLTree avt, ElemType key, AVLTree* p_pos);

//
// B 树
// 
// 注意：
//	B 树的英文名为 B-tree，因此有翻译为 B- 树，实际上 - 只是连字符，正确翻译应该是 B 树。除 B 树外，还有基于 B 树的 B+ 树和 B* 树。
// 
// 背景：
//	二叉排序树、平衡二叉树等数据结构，适用于在内存中查找数据总量较小的数据。当数据量非常大，内存无法放下时，就需要用外存（硬盘）来存储。
//	查找硬盘中存放的数据时，限制其查找效率的瓶颈主要在于硬盘的访问次数和单次访问时长，算法本身的效率影响相对较小。硬盘的单次访问时长一
//	般是固定的，主要跟硬盘的硬件规格和操作系统对硬盘访问的实现（实际上，考虑到硬盘访问的时间代价，操作系统一般会在每次访问硬盘时，除了
//	读取目标地址的数据外，还会额外读取其相邻地址的数据。一次读取的数据总量一般为 4KB 或 8KB，称为一页。所以，从硬盘中读取 1B 数据和读
//	取 4KB 或 8KB 数据的时间成本几乎相同。）有关。因此，提升硬盘中数据查找效率的主要方式，就是减少硬盘访问次数。
// 
//	假设在硬盘中使用平衡二叉树存储数据，则查找数据时，每读取一个结点的数据，就要进行一次硬盘访问。若树的高度为 H，则最坏情况下，完成查
//	找共需要进行 H 次硬盘访问。根据操作系统对硬盘读取的优化处理，可以想到，适当增加每个结点包含的数据个数（顺序存储以确保地址相邻），
//	可以在不增加单次访问时长的情况下，一次读取多个数据进行比对，因为数据总量是固定的，因此硬盘访问次数将减少，查找效率将得到提升。
// 
//	B 树正是在该背景下出现，B 树和其变形 B+ 树、B* 树一起，被广泛用于数据库和文件系统的实现。
// 
// 定义：
//	B 树又名平衡多路查找树，是二叉查找树的一般化，每个结点都可以有两个以上的子结点。通常我们称 m (m >= 3) 阶的 B 树，具备以下性质：
//		1. 每个结点最多有 m 个子结点；
//		2. 根结点至少有 2 个子结点（当根结点同时是叶子结点除外）；
//		3. 非根非叶结点至少有 [(m / 2) 向上取整] 个子结点；
//		4. 每个结点的结构为：| n | P0 | K1 | P1 | K2 |...| Kn | Pn |，其中：
//			n 是该结点中包含的关键字个数，[(m / 2) 向上取整] - 1 < n < m - 1；
//			K1 ~ Kn 是具体的关键字且：K1 < K2，K2 < K3...即关键字按大小关系递增；
//			P0 ~ Pn 是指向子结点的指针且：P0 结点关键字均小于 K1，P1 结点关键字均大于 K1 小于 K2，... Pn 结点关键字均大于 Kn；
//		5. 所有叶子结点均位于同一层（即深度相同）且不包含任何信息（因此叶子结点并不需要实际存储下来，指向叶子结点的指针均为 NULL）。
// 
// 插入：
//	设 B 树为 T，阶为 m，结点中包含的关键字个数范围为：min ~ max，即：min = ([(m / 2) 向上取整] - 1)，max = (m - 1)；
//	
//	设待插入的关键字为 k，则：
//	1. 从 T 的根结点开始，寻找 k 要插入的目标结点 C；
//	2. 若根结点为 NULL，则新建结点作为根结点，将 k 放入其中，完成插入，否则设置 C = 根结点；
//	4. 依次将结点 C 中的关键字同 k 进行比较，若等于 k 则插入失败，否则 k 必将位于某个关键字的左侧或右侧；
//	5. 假设 k 应位于某个关键字的左侧（右侧同理），则查看该关键字左侧的指针：
//		若非 NULL，则设 C = 左侧指针指向的结点，然后回到步骤 4 重新执行；
//		若为 NULL，则将 k 放入该关键字左侧；
//	6. 判断结点 C 中包含的关键字个数是否大于 max：
//		若否，则插入完成；
//		若是，则查找 C 中 (max / 2) 位置的关键字，设为 s；
//	7. 新建一个结点 N，将结点 C 中 s 左侧的关键字全部移入 N 中，s 右侧的关键字仍保留在 C 中；
//	8. 将 s 移入结点 C 的父结点（若无则新建）中，通过比对找到合适位置，并将 s 左侧指针指向 N，将 s 右侧指针指向 C；
//	9. 设置 C = C 的父结点，然后回到步骤 6 重新执行。
// 
//	备注：
//		1. B 树的创建是通过插入实现；
//		2. B 树插入时并不需要每次都新建结点；
//		3. 待插入的关键字总是落在最底层非叶结点上，然后再根据需要进行结点拆分。
// 
// 查找：
//	设 B 树为 T，待查找的关键字为 k，k 所在结点为 C，则：
//	1. 设 C = T 的根结点；
//	2. 依次将 k 与 C 中的关键字进行比较，若等于则查找成功，返回 C，否则 k 必位于某个关键字的左侧或右侧；
//	3. 假设 k 位于某个关键字的左侧（右侧同理），则查看该关键字左侧的指针：
//		若非 NULL，则设 C = 左侧指针指向的结点，然后回到步骤 2 重新执行；
//		若为 NULL，则查找失败，返回 NULL。
// 
// 删除：
//	设 B 树为 T，阶为 m，结点中包含的关键字个数范围为：min ~ max，即：min = ([(m / 2) 向上取整] - 1)，max = (m - 1)；
// 
//	设待删除的关键字为 k，则：
//	1. 查找到 k 所在目标结点 C，若 C 为 NULL，则删除失败，若 C 非 NULL，则继续步骤 2；
//	2. 若 C 为最底层非叶结点，则：
//		(1).若 C 中包含的关键字个数大于 min，则从 C 中删除 k；
//		(2).若 C 中包含的关键字个数等于 min，且 C 相邻的右兄弟（或左兄弟）结点中关键字个数大于 min，则：
//			首先，从 C 中删除 k；
//			然后，将该兄弟结点中的最小（或最大）关键字移入其父结点中；
//			最后，将父结点中相邻且小于（或大于）该移入关键字的关键字移入 C 中；
//		(3).若 C 中包含的关键字个数等于 min，且 C 相邻的右兄弟（或左兄弟）结点中关键字个数等于 min，则：
//			首先，从 C 中删除 k；
//			然后，设 C 的父结点为 F，F 中指向 C 相邻兄弟结点的指针为 Pi，相同索引的关键字为 Ki，将 C 剩余的关键字和 Ki 一起移入兄弟结点；
//			最后，释放 C 指向的结点空间，判断 F 中关键字个数是否小于 min：
//				若否，则删除完成；
//				若是，则设 C = F，回到“然后”步骤重新执行。
//

//
// B+ 树
// 
// 定义：
//	B+ 树是 B 树的一种变形，相比 B 树主要有以下不同：
//		1. 结点的关键字个数等于结点的子结点个数（B 树结点的关键字个数比子结点个数少 1）；
//		2. 结点中每个关键字都等于其对应子结点中最大的关键字（即 Ki 等于 Pi 指向的子结点中最大的关键字）；
//		3. 每个叶子结点都包含关键字，并符合从左到右递增的顺序，所有叶子结点中的关键字合在一起就是整棵树的全部关键字。
// 
// 特点：
//	1. B+ 树查询时需要的硬盘 I/O 更少；
//	2. B+ 树的查询均发生在叶子结点，查询性能稳定；
//	3. B+ 树的叶子结点形成有序链表，范围查询方便。
//

//
// B* 树
// 
// 定义：
//	B* 树是 B+ 树的一种变形，相比 B+ 树主要有以下不同：
//		1. 非根非叶结点至少有 [(3 * m / 2) 向上取整] 个关键字（B+ 树是 [(m / 2) 向上取整] 个）；
//		2. 非根非叶结点增加指向兄弟结点的指针，调整结点的合并拆分规则以减少增删关键字导致的结点拆分和合并次数。
// 
// 特点：
//	1. B* 树的空间利用率更高；
//	2. B* 树增删操作性能更好。
//

//
// 哈希表
// 
// 背景：
//	对于二叉排序树、B 树等数据结构来说，查找关键字时，都是从根结点开始，不断取出结点内的关键字或索引值与待查找的关键字进行比较，
//	直至找到匹配的结点。那么，有没有一种数据结构，可以根据给定的查找关键字，直接确认目标所在的位置，省去逐个比较的过程，从而提
//	升查找效率？答案是肯定的，这种数据结构就是哈希表（Hash Table），而根据关键字直接确认目标所在位置的方法，就是哈希函数。
// 
// 定义：
//	哈希表是基于哈希函数建立的一种查找表，可以根据给定的查找关键字，直接得出目标所在位置（哈希地址）。
// 
// 构建：
//	哈希表的构建主要包含两个关键操作：一是设计合适的哈希函数，二是设计合适的哈希冲突解决函数。
// 
//	哈希函数：
//		哈希函数就是一个普通函数，它接收给定的查找关键字作为变量，然后通过特定的计算规则，输出对应的哈希地址。注意：哈希
//		地址是目标元素在哈希表中的存储位置，而不是实际的内存地址。
// 
//		设计哈希函数，关键是设计出合适的计算规则，常用的设计思路有 6 种：
//			1. 直接定址法：
//				哈希函数是关于关键字的一次函数，即 H(key) = a * key + b，其中 a 和 b 是常数；
//			2. 数字分析法：
//				抽取关键字中若干位作为哈希地址；
//			3. 平方取中法：
//				对关键字做平方操作，然后取结果的中间若干位作为哈希地址；
//			4. 折叠法：
//				将关键字分为位数相同的若干部分（无法均分时可以有一个部分位数不同），然后取这几个
//				部分的叠加和（舍去进位）作为哈希地址；
//			5. 除留余数法：
//				若已知哈希表的最大长度为 m，取一个小于等于 m 的值 s，对关键字做取余运算，结果即
//				哈希地址，即 H(key) = key % s，其中 s 一般为小于等于 m 的质数或不包含小于 20
//				的质因子的合数；
//			6. 随机数法：
//				取关键字的一个随机函数值作为哈希地址，即 H(key) = random(key)，注意这里的随机
//				函数 random 是伪随机函数，因为对于真正的随机函数来说，即使每次给定的 key 相同，
//				其输出的结果也不同，而伪随机函数则相反，相同的 key 总是输出相同的结果。
// 
//		对哈希函数来说，可能出现不同的关键字对应相同哈希地址的情况。比如我们要使用哈希表存储一系列人名，设计的哈希函数是：
//		将人名首字母的 ASCII 码作为该人名的哈希地址。对于 Jim 和 Jack 来说，对应的哈希地址就是一样的，这称为哈希冲突。
// 
//		无论怎么设计哈希函数，哈希冲突都只能尽量减少，无法完全避免，因此，还需为哈希函数配备合适的冲突解决函数以解决冲突。
// 
//	哈希冲突：
//		哈希冲突即哈希函数为不同的关键字生成了相同的哈希地址，解决哈希冲突的思路一般有以下 4 种：
//			1. 开放定址法：
//				对发生冲突的关键字 key，调用 H(key) = (H(key) + d) % m 再次计算哈希地址，
//				其中 m 是哈希表长度，d 是一个变量。具体来说，就是当冲突发生时，通过以下 3 种
//				方式之一获取 d 值，然后再次计算，直到计算出的哈希地址不再冲突为止。d 的 3 种
//				获取方式为：
//					(1). 线性探测：d = 1, 2, 3, ..., m - 1； 
//					(2). 平方探测：d = 1²，-1², 2², -2², ...；
//					(3). 随机探测：d = random(d)，random 是伪随机函数。
//			2. 再散列法：
//				事先准备若干哈希函数，如果第一个哈希函数出现冲突，就使用第二个，依次类推；
//			3. 链地址法：
//				将所有产生冲突的关键字对应的数据元素存储在同一个线性链表中；
//			4. 公共溢出区法：
//				为哈希表配备两个存储空间，一个存放没发生冲突的数据，一个存放发生冲突的数据。
// 查找：
//	哈希表的查找操作同构建过程类似，对于给定的关键字 k，通过哈希函数求出哈希地址：
//		1. 若地址中没有数据，则查找失败；
//		2. 否则，将该数据对应的关键字（设为 k'）与 k 进行比较：
//			(1). 若 k' == k，则查找成功；
//			(2). 否则，说明存在冲突，根据冲突解决函数计算新的哈希地址，然后回到步骤 1 重新执行。
// 
//	由于哈希冲突的存在，使得哈希表的查找算法仍会涉及比较，因此仍需使用平均查找长度 ASL 来衡量哈希表的查找效率。
// 
//	哈希表查找过程中需要进行的比较次数取决于以下 3 个因素：
//		1. 哈希函数：哈希函数的好坏决定冲突出现的频次，但一般情况下，相比后两种因素，哈希函数的影响可以忽略不计；
//		2. 冲突解决函数：不同的冲突解决函数，即使关键字和哈希函数都相同，对应查找算法的 ASL 也会存在明显差别；
//		3. 哈希表的装填因子：装填因子 = 哈希表中数据的个数 / 哈希表的长度，表示哈希表的疏密程度。
// 
//	已有数学公式可以证明，在冲突解决函数相同的情况下，哈希表的 ASL 只同装填因子有关，同哈希表中的数据个数无关。
//	装填因子越小，哈希表中空闲位置越多，发生冲突的概率越低，平均查找长度越小；反之，哈希表中空闲位置越少，发生
//	冲突的概率越高	，平均查找长度越大。不过，装填因子也不是越小越好，还要同时考虑空间利用率的问题，装填因子太小，
//	会导致空间利用率太低。
// 
//	通常认为，装填因子 = 0.75 时时间和空间综合利用率最高。
//

/*
* 哈希表最大长度
*/
#define MAX_HASH_SIZE 100

/*
* 采用链地址法解决冲突的哈希表结构体
*/
typedef struct
{
	LinkList* larr; // 存储指向哈希地址对应数据所在线性链表的指针的数组，数组下标即哈希地址
	int count; // 当前哈希表中存放的数据个数
}HashTable;

/*
* 哈希函数（除留余数法实现）
*/
int Hash(int key);

/*
* 初始化哈希表
*/
void InitHashTable(HashTable* p_ht);

/*
* 哈希表插入数据
* 
* 使用数据本身作为代表数据的关键字
*/
void InsertHashTable(HashTable* p_ht, ElemType e);

/*
* 哈希表查找数据
* 
* 此处用于查找的关键字即数据本身
* 
* 成功指向数据所在结点的指针，失败返回 NULL
*/
LNode* SearchHashTable(HashTable ht, int key);

#endif // !_WYL_SEARCH
